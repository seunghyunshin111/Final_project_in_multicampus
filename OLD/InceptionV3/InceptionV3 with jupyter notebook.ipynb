{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikidocs.net/39964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b97b2e7ad625>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/tmp/text-embedding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "m = hub.Module(\"/tmp/text-embedding\")\n",
    "embeddings = m(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jsideas.net/Inception_v3_transfer_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 299\n",
    "MODEL_INPUT_HEIGHT = 299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "    \"\"\"이미지 디렉토리에서 인풋 데이터를 찾아 데이터로 변환한다\"\"\"\n",
    "    \n",
    "    ## image_dir가 존재하지 않는다면 오류 출력\n",
    "    if not gfile.Exists(image_dir):\n",
    "        print(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    ### image_dir 내 하위 디렉토리(label)를 가져온다 \n",
    "    sub_dirs = [x[0] for x in gfile.Walk(image_dir)]\n",
    "    \n",
    "    is_root_dir = True\n",
    "    for sub_dir in sub_dirs:\n",
    "        if is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "        extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "        \n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "            \n",
    "        print(\"Looking for images in '\" + dir_name + \"'\")\n",
    "        for extension in extensions:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(gfile.Glob(file_glob))\n",
    "        \n",
    "        ## 파일이 없거나 데이터가 작으면 예외 처리\n",
    "        if not file_list:\n",
    "            print('No files found')\n",
    "            continue\n",
    "        if len(file_list) < 20:\n",
    "            print(\"WARNING: Folder has less than 20 images, which may cause issues.\")\n",
    "        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "            print(\"WARNING: Folder {} has more than {} images. Some images will never be selected\".format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        \n",
    "        ## 트레이닝 / 밸리데이션 / 테스트셋으로 나눈다.\n",
    "        training_images = []\n",
    "        testing_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            \n",
    "            hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                               (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                              (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "            \n",
    "            if percentage_hash < validation_percentage:\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "        \n",
    "        result[label_name] = {\n",
    "            'dir': dir_name,\n",
    "            'training': training_images,\n",
    "            'testing': testing_images,\n",
    "            'validation': validation_images,\n",
    "        }\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 다운로드받을 때 사용할 Tqdm 클래스를 정의한다.\n",
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "    dest_directory = model_dir\n",
    "    ensure_dir_exists(dest_directory)\n",
    "    \n",
    "    filename = DATA_URL.split(\"/\")[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        \n",
    "        print(\"그래프 파일이 없습니다. 다운로드를 시작합니다.\")\n",
    "        \n",
    "        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=DATA_URL) as t:\n",
    "            urllib.request.urlretrieve(DATA_URL, filepath, reporthook=t.update_to, data=None)\n",
    "        \n",
    "        statinfo = os.stat(filepath)\n",
    "        print(\"다운로드 완료: \", filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print(\"그래프 파일이 이미 존재합니다.\")\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_graph():\n",
    "    \"\"\"\n",
    "    저장된 GraphDef 파일에서 그래프를 만들고\n",
    "    Graph 오브젝트를 리턴한다.\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_filename = os.path.join(model_dir, 'classify_image_graph_def.pb')\n",
    "    \n",
    "        with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "                tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "                    BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME, RESIZED_INPUT_TENSOR_NAME]))\n",
    "    return graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_distort_images(flip_left_right, random_crop, random_scale, random_brightness):\n",
    "    \"\"\"이미지 데이터에 변화를 줄지 결정한다.\"\"\"\n",
    "    return (flip_left_right or (random_crop != 0) or (random_scale != 0) or (random_brightness != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor):\n",
    "    how_many_bottlenecks = 0\n",
    "    ensure_dir_exists(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, \\\n",
    "                                         bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)\n",
    "                how_many_bottlenecks += 1\n",
    "                if how_many_bottlenecks % 100 == 0:\n",
    "                    print('{} bottleneck files created'.format(how_many_bottlenecks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, \\\n",
    "                             bottleneck_dir, jpeg_data_tensor, bottleneck_tensor):\n",
    "    label_lists = image_lists[label_name]\n",
    "    sub_dir = label_lists['dir']\n",
    "    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "    ensure_dir_exists(sub_dir_path)\n",
    "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
    "                                    bottleneck_dir, category)\n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                               image_dir, category, sess, jpeg_data_tensor,\n",
    "                               bottleneck_tensor)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneck_string = bottleneck_file.read()\n",
    "    \n",
    "    did_hit_error = False\n",
    "    try:\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    except ValueError:\n",
    "        print('Invalid float found, recreating bottleneck')\n",
    "        did_hit_error = True\n",
    "    if did_hit_error:\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                               image_dir, category, sess, jpeg_data_tensor,\n",
    "                               bottleneck_tensor)\n",
    "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "            bottleneck_string = bottleneck_file.read()\n",
    "        # Allow exceptions to propagate here, since they shouldn't happen after a\n",
    "        # fresh creation\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category):\n",
    "    return get_image_path(image_lists, label_name, index, bottleneck_dir, category) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    \n",
    "    if label_name not in image_lists:\n",
    "        tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "    label_lists = image_lists[label_name]\n",
    "    \n",
    "    if category not in label_lists:\n",
    "        tf.logging.fatal('Category does not exist %s.', category)\n",
    "    category_list = label_lists[category]\n",
    "    \n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.', label_name, category)\n",
    "        \n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    \n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir,\n",
    "                          category, sess, jpeg_data_tensor, bottleneck_tensor):\n",
    "    print('보틀넥 파일 생성 시작 - {}'.format(bottleneck_path))\n",
    "    image_path = get_image_path(image_lists, label_name, index, image_dir, category)\n",
    "    \n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fata('File does nto exist %s', image_path)\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    \n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(\n",
    "            sess, image_data, jpeg_data_tensor, bottleneck_tensor)\n",
    "    except:\n",
    "        raise RuntimeError('파일 처리 중 에러 발생: %s' % image_path)\n",
    "        \n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor, bottleneck_tensor):\n",
    "    bottleneck_values = sess.run(\n",
    "        bottleneck_tensor, {image_data_tensor: image_data})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "            bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\n",
    "            name='BottleneckInputPlaceholder')\n",
    "        \n",
    "        ground_truth_input = tf.placeholder(tf.float32, [None, class_count], name='GroundTruthInput')\n",
    "        \n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count], stddev=0.01)\n",
    "            \n",
    "            layer_weights = tf.Variable(initial_value, name='final_weight')\n",
    "        \n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "            \n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "    \n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=ground_truth_input, logits=logits)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "        \n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)\n",
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(\n",
    "                prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category, bottleneck_dir, image_dir,\n",
    "                                 jpeg_data_tensor, bottleneck_tensor):\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if how_many >= 0:\n",
    "        # 샘플링한 보틀넥을 가져온다.\n",
    "        for unused_i in range(how_many):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(image_lists.keys())[label_index]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                      image_dir, category)\n",
    "            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                                image_index, image_dir, category,\n",
    "                                                bottleneck_dir, jpeg_data_tensor,\n",
    "                                                bottleneck_tensor)\n",
    "            ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "            ground_truth[label_index] = 1.0\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(ground_truth)\n",
    "            filenames.append(image_name)\n",
    "    else:\n",
    "        # 보틀넥을 모두 가져온다.\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(image_lists[label_name][category]):\n",
    "                image_name = get_image_path(image_lists, label_name, image_index,\n",
    "                                            image_dir, category)\n",
    "                bottleneck = get_or_create_bottleneck(sess, image_lists, label_name,\n",
    "                                                      image_index, image_dir, category,\n",
    "                                                      bottleneck_dir, jpeg_data_tensor,\n",
    "                                                      bottleneck_tensor)\n",
    "                ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "                ground_truth[label_index] = 1.0\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(ground_truth)\n",
    "                filenames.append(image_name)\n",
    "    return bottlenecks, ground_truths, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'cat_photos'\n",
    "output_graph = '/tmp/output_graph.pb'\n",
    "output_labels = '/tmp/output_labels.txt'\n",
    "summaries_dir = '/tmp/retrain_logs'\n",
    "how_many_training_steps = 300\n",
    "learning_rate = 0.01\n",
    "testing_percentage = 10\n",
    "validation_percentage = 10\n",
    "eval_step_interval = 10\n",
    "train_batch_size = 100\n",
    "test_batch_size = -1\n",
    "validation_batch_size = 100\n",
    "print_misclassified_test_images = False\n",
    "model_dir = '/tmp/imagenet'\n",
    "bottleneck_dir = '/tmp/bottleneck'\n",
    "final_tensor_name = 'final_result'\n",
    "flip_left_right = False\n",
    "random_crop = 0\n",
    "random_scale = 0\n",
    "random_brightness = 0 \n",
    "log_frequency = 10\n",
    "log_device_placement = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 파일이 없습니다. 다운로드를 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz: 88.9MB [00:02, 38.3MB/s]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 완료:  inception-2015-12-05.tgz 88931400 bytes.\n"
     ]
    }
   ],
   "source": [
    "## inception_v3를 다운받아 압축을 푼다.\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'GraphDef'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-49e899b43e0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 그래프와 보틀넥 텐서, 이미지데이터 텐서, 리사이즈 이미지 텐서를 불러온다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottleneck_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjpeg_data_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_image_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcreate_inception_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-fd2fe75e0e80>\u001b[0m in \u001b[0;36mcreate_inception_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'GraphDef'"
     ]
    }
   ],
   "source": [
    "## 그래프와 보틀넥 텐서, 이미지데이터 텐서, 리사이즈 이미지 텐서를 불러온다.\n",
    "graph, bottleneck_tensor, jpeg_data_tensor, resize_image_tensor = (create_inception_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image directory 'cat_photos' not found.\n"
     ]
    }
   ],
   "source": [
    "## 재학습할 폴더를 가져와서 레이블화한다.\n",
    "image_lists = create_image_lists(image_dir, testing_percentage, validation_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f90c59fe0390>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclass_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_lists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "class_count = len(image_lists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if class_count == 0:\n",
    "    print('이미지가 해당 경로에 없습니다: ' + image_dir)\n",
    "    \n",
    "elif class_count == 1:\n",
    "    print('해당 경로에 클래스가 1개만 발견되었습니다: ' + image_dir + ' - 분류를 위해 2개 이상의 클래스가 필요합니다.')\n",
    "    \n",
    "else:\n",
    "    print(\"클래스가 2개 이상 있습니다. 학습을 시작합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image distortion // 현재 설정: False\n",
    "do_distort_images = should_distort_images(flip_left_right, random_crop, random_scale, random_brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    if do_distort_images:\n",
    "        (distorted_jpeg_data_tensor, distorted_image_tensor) = add_input_distortion(\n",
    "            flip_left_right, random_crop, random_scale, random_brightness)\n",
    "    else:\n",
    "        cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)\n",
    "    \n",
    "    ## 네트워크의 끝에 우리가 원하는 분류 레이어를 붙인다.\n",
    "    (train_step, cross_entropy, bottleneck_input, \n",
    "     ground_truth_input, final_tensor) = add_final_training_ops(len(image_lists.keys()), \n",
    "                                                                final_tensor_name, \n",
    "                                                                bottleneck_tensor)\n",
    "        \n",
    "    ## 정확도 평가를 위한 새로운 오퍼레이션\n",
    "    evaluation_step, prediction = add_evaluation_step(final_tensor, ground_truth_input)\n",
    "    \n",
    "    ## 가중치 초기화\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(how_many_training_steps):\n",
    "        \n",
    "        ## 보틀넥과 정답지를 준비한다.\n",
    "        if do_distort_images:\n",
    "            (train_bottlenecks, train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "                sess, image_lists, train_batch_size, 'training', image_dir, distorted_jpeg_data_tensor,\n",
    "                distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "        else:\n",
    "            (train_bottlenecks, train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "                sess, image_lists, train_batch_size, 'training', bottleneck_dir, image_dir,\n",
    "                jpeg_data_tensor, bottleneck_tensor)\n",
    "        \n",
    "        \n",
    "        ## 보틀넥과 정답지를 모델에 집어넣어 학습시킨다.\n",
    "        _ = sess.run(\n",
    "            [train_step],\n",
    "            feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                      ground_truth_input: train_ground_truth})\n",
    "    \n",
    "        ## 특정 구간마다 트레이닝 정확도와 cross entropy 로그, 밸리데이션 정확도를 출력한다.\n",
    "        is_last_step = (i + 1 == how_many_training_steps)\n",
    "        if (i % eval_step_interval) == 0 or is_last_step:\n",
    "            train_accuracy, cross_entropy_value = sess.run(\n",
    "                [evaluation_step, cross_entropy],\n",
    "                feed_dict = {bottleneck_input: train_bottlenecks,\n",
    "                            ground_truth_input: train_ground_truth})\n",
    "            \n",
    "            print('%s: Step %d: Train accuracy = %.1f%%'% (datetime.now(), i, train_accuracy * 100))\n",
    "            print('%s: Step %d: Cross entropy = %f' % (datetime.now(), i, cross_entropy_value))\n",
    "            \n",
    "            validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                get_random_cached_bottlenecks(\n",
    "                    sess, image_lists, validation_batch_size, 'validation', bottleneck_dir,\n",
    "                    image_dir, jpeg_data_tensor, bottleneck_tensor))\n",
    "            \n",
    "            validation_accuracy = sess.run(\n",
    "                evaluation_step,\n",
    "                feed_dict = {bottleneck_input: validation_bottlenecks,\n",
    "                            ground_truth_input: validation_ground_truth})\n",
    "            print('%s: Step %d: Validation accuracy = %.1f%% (N=%d)'% (datetime.now(), i,\n",
    "                                                                       validation_accuracy * 100, \n",
    "                                                                       len(validation_bottlenecks)))\n",
    "            \n",
    "            ## 시각화를 위해 로그를 한벌 더 저장한다.\n",
    "            acc_list.append({\"epoch\": i, \"train_accuracy\": train_accuracy, \"validation_accuracy\": validation_accuracy})\n",
    "    \n",
    "    ## 테스트셋에 사용할 보틀넥과 정답지를 가져온다.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(sess, image_lists, test_batch_size, 'testing', bottleneck_dir,\n",
    "                                     image_dir, jpeg_data_tensor, bottleneck_tensor))\n",
    "    \n",
    "    ## 테스트셋 정확도와 예측 분류값을 가져온다.\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction], \n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                  ground_truth_input: test_ground_truth})\n",
    "    print('최종 학습 정확도 = %.1f%% (N=%d)' % (test_accuracy * 100, len(test_bottlenecks)))\n",
    "    \n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "        sess, graph.as_graph_def(), [final_tensor_name])\n",
    "    with gfile.FastGFile(output_graph, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    with gfile.FastGFile(output_labels, 'w') as f:\n",
    "        f.write('\\n'.join(image_lists.keys()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "acc_df = pd.DataFrame.from_dict(acc_list)\n",
    "acc_df.set_index('epoch', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "acc_df.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'tmp/test_chartreux.jpg'                                      \n",
    "modelFullPath = '/tmp/output_graph.pb'                                    \n",
    "labelsFullPath = '/tmp/output_labels.txt'                                 \n",
    "\n",
    "\n",
    "def create_graph():\n",
    "    \"\"\"저장된(saved) GraphDef 파일로부터 graph를 생성하고 saver를 반환한다.\"\"\"\n",
    "    with tf.gfile.FastGFile(modelFullPath, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_image(imagePath):\n",
    "    answer = None\n",
    "\n",
    "    if not tf.gfile.Exists(imagePath):\n",
    "        tf.logging.fatal('파일이 존재하지 않습니다: %s', imagePath)\n",
    "        return answer\n",
    "\n",
    "    image_data = tf.gfile.FastGFile(imagePath, 'rb').read()\n",
    "\n",
    "    # 저장된(saved) GraphDef 파일로부터 graph를 생성한다.\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        ## 학습이 끝난 마지막 소프트맥스 텐서를 가져온다.\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        ## 이미지 데이터를 네트워크 맨 앞에 넣어 분류를 실행한다.\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                               {'DecodeJpeg/contents:0': image_data})\n",
    "        ## [[]]로 중첩된 어레이가 떨어지는데 np.squeeze로 하나의 어레이로 만든다.\n",
    "        predictions = np.squeeze(predictions)\n",
    "        \n",
    "        ## 가장 높은 확률 값을 가진 5개를 선택한다. 여기서는 클래스가 3개 뿐이라 3개만 출력된다.\n",
    "        top_k = predictions.argsort()[-5:][::-1]\n",
    "        print(top_k)\n",
    "        f = open(labelsFullPath, 'rb')\n",
    "        lines = f.readlines()\n",
    "        labels = [str(w).replace(\"\\n\", \"\") for w in lines]\n",
    "        for node_id in top_k:\n",
    "            human_string = labels[node_id]\n",
    "            score = predictions[node_id]\n",
    "            print('%s (score = %.5f)' % (human_string, score))\n",
    "\n",
    "        answer = labels[top_k[0]]\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image('tmp/test_chartreux.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image('tmp/test_russian_blue.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
